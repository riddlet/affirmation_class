{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 2196016 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "__docformat__ = 'restructedtext en'\n",
    "import timeit\n",
    "import numpy\n",
    "import scipy.io\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "import sys\n",
    "BASE_DIR = '/Users/travis/Documents/Gits/'\n",
    "GLOVE_DIR = BASE_DIR + '/Data/'\n",
    "#MAX_SEQUENCE_LENGTH = 210\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.840B.300d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for custom metrics\n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import get_from_module\n",
    "\n",
    "def categorical_accuracy(y_true, y_pred):\n",
    "    \"\"\"Categorical accuracy metric.\n",
    "\n",
    "    Computes the mean accuracy rate across all predictions for\n",
    "    multiclass classification problems.\n",
    "    \"\"\"\n",
    "    return K.mean(K.equal(K.argmax(y_true, axis=-1),\n",
    "                          K.argmax(y_pred, axis=-1)))\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dat(df_ess, df_dem):\n",
    "    df_ess = df_ess[df_ess.Study=='Connecticut']\n",
    "    df_ess.Condition.replace(['c', 'c2', 'c1', 'c3', 'ca', 'cb', '3'], 'Control', inplace=True)\n",
    "    df_ess.Condition.replace(['t', 't2', 't3', 't1', '1', '2', 'ta', 'tb'], 'Treatment', inplace=True)\n",
    "    df_ess.Condition.replace(['c/t'], np.nan, inplace=True)\n",
    "    \n",
    "    df_dem = df_dem[df_dem.Study=='Connecticut']\n",
    "    df_dem.Ethnicity.replace('Asian', 'Asian American', inplace=True)\n",
    "    df_dem.Ethnicity.replace('Other/Mixed', 'Other', inplace=True)\n",
    "    df_dem = df_dem[['ID', 'Ethnicity', 'Gender']].dropna()\n",
    "    \n",
    "    outdat = pd.merge(df_ess[['ID', 'Intervention_number', 'Essay', 'Condition', 'Intervention_Date', 'corrected']], \n",
    "                    df_dem, how='left', on='ID').drop_duplicates()\n",
    "    \n",
    "    return(outdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here, we're preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travis/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travis/anaconda/lib/python2.7/site-packages/pandas/core/generic.py:3430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1232 total students\n",
      "f    3315\n",
      "m    2909\n",
      "Name: Gender, dtype: int64\n",
      "Control      3473\n",
      "Treatment    2751\n",
      "Name: Condition, dtype: int64\n",
      "mean essay length = 42.8125\n",
      "sd essay length = 23.8684140013\n",
      "Found 6224 texts.\n",
      "Gender  Condition\n",
      "f       Control      1851\n",
      "        Treatment    1464\n",
      "m       Control      1622\n",
      "        Treatment    1287\n",
      "dtype: int64\n",
      "Found 5816 unique tokens.\n",
      "Shape of data tensor: (6224, 208)\n",
      "Shape of label tensor: (6224, 4)\n",
      "Shape of xtrain tensor: (4497, 208)\n",
      "Shape of ytrain tensor: (4497, 4)\n",
      "Shape of xval tensor: (793, 208)\n",
      "Shape of yval tensor: (793, 4)\n",
      "Shape of xtest tensor: (934, 208)\n",
      "Shape of ytest tensor: (934, 4)\n",
      "Preparing embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "df_ess = pd.read_csv('../../Data/3 CSV Files/essays1.23.16.csv', sep='|')\n",
    "df_dem = pd.read_csv('../../Data/3 CSV Files/demog3.2.16.csv')\n",
    "df = create_dat(df_ess, df_dem)\n",
    "df.dropna(axis=0, subset=['corrected', 'Condition'], inplace=True)\n",
    "df['word_count'] = df.corrected.apply(lambda x: len(x.split()))\n",
    "print('Found %s total students' % len(df.ID.value_counts()))\n",
    "print(df.Gender.value_counts())\n",
    "print(df.Condition.value_counts())\n",
    "print('mean essay length = %s' % np.mean(df.word_count))\n",
    "print('sd essay length = %s' % np.std(df.word_count))\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "labels_index['conm']=0\n",
    "labels_index['conf']=1\n",
    "labels_index['affm']=2\n",
    "labels_index['afff']=3\n",
    "texts = df[\"corrected\"].tolist()\n",
    "labelsType = df[\"Condition\"].tolist()\n",
    "labelsRace = df[\"Gender\"].tolist()\n",
    "labelsCombined=[]\n",
    "for i in range(len(labelsType)):\n",
    "    if labelsType[i]=='Control' and labelsRace[i]=='m':\n",
    "        labelsCombined.append(0)\n",
    "    elif labelsType[i]=='Control' and labelsRace[i]=='f':\n",
    "        labelsCombined.append(1)\n",
    "    elif labelsType[i]=='Treatment' and labelsRace[i]=='m':\n",
    "        labelsCombined.append(2)\n",
    "    elif labelsType[i]=='Treatment' and labelsRace[i]=='f':\n",
    "        labelsCombined.append(3)\n",
    "        \n",
    "print('Found %s texts.' % len(texts))\n",
    "\n",
    "print(df.groupby(['Gender', 'Condition']).size())\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "maxseqval=0\n",
    "for i in range(len(sequences)):\n",
    "    if len(sequences[i])>maxseqval:\n",
    "        maxseqval=len(sequences[i])\n",
    "        \n",
    "MAX_SEQUENCE_LENGTH = maxseqval\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labelsCombined))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=.15)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = x_train[indices]\n",
    "labels = y_train[indices]\n",
    "VALIDATION_SPLIT = 0.15\n",
    "#TEST_SPLIT = 0.15\n",
    "nb_val_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "#nb_validation_samples = int(VALIDATION_SPLIT * (data.shape[0]-nb_test_samples))\n",
    "\n",
    "\n",
    "x_val = data[-nb_val_samples:]\n",
    "y_val = labels[-nb_val_samples:]\n",
    "#y_val=np.swapaxes(np.tile(y_val, (MAX_SEQUENCE_LENGTH, 1, 1)),0,1)\n",
    "#y_train=np.swapaxes(np.tile(y_train, (MAX_SEQUENCE_LENGTH, 1, 1)),0,1)\n",
    "x_train = data[:-nb_val_samples]\n",
    "y_train = labels[:-nb_val_samples]\n",
    "\n",
    "textstest=[]\n",
    "textsshuff=[]\n",
    "for i in indices:\n",
    "  textsshuff.append(texts[i])\n",
    "index_word={}\n",
    "for i,x in word_index.items():\n",
    "    index_word[x]=i\n",
    "textstest=textsshuff[:nb_val_samples]\n",
    "\n",
    "thefile = open('../output/gendercleantimedistmodeltesttexts.txt', 'w')\n",
    "for item in textstest:\n",
    "  thefile.write(\"%s\\n\" % item)  \n",
    "\n",
    "np.save('../output/gendercleantimedistmodelxtest.npy', x_test)\n",
    "np.save('../output/gendercleantimedistmodelytest.npy', y_test)\n",
    "\n",
    "print('Shape of xtrain tensor:', x_train.shape)\n",
    "print('Shape of ytrain tensor:', y_train.shape)\n",
    "print('Shape of xval tensor:', x_val.shape)\n",
    "print('Shape of yval tensor:', y_val.shape)\n",
    "print('Shape of xtest tensor:', x_test.shape)\n",
    "print('Shape of ytest tensor:', y_test.shape)\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "# prepare embedding matrix\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(nb_words + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 208, 300)      1745100     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 208, 300)      0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 50)            70200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4)             204         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,815,504\n",
      "Trainable params: 1,815,504\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True,dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels_index), activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4497 samples, validate on 793 samples\n",
      "Epoch 1/35\n",
      "4497/4497 [==============================] - 29s - loss: 1.2531 - precision: 0.4415 - recall: 0.0936 - fmeasure: 0.1454 - categorical_accuracy: 0.3816 - val_loss: 0.9426 - val_precision: 0.5616 - val_recall: 0.3468 - val_fmeasure: 0.4286 - val_categorical_accuracy: 0.5208\n",
      "Epoch 2/35\n",
      "4497/4497 [==============================] - 29s - loss: 1.0176 - precision: 0.5270 - recall: 0.2906 - fmeasure: 0.3727 - categorical_accuracy: 0.4721 - val_loss: 0.8656 - val_precision: 0.5524 - val_recall: 0.4855 - val_fmeasure: 0.5167 - val_categorical_accuracy: 0.5397\n",
      "Epoch 3/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.9405 - precision: 0.5403 - recall: 0.3725 - fmeasure: 0.4402 - categorical_accuracy: 0.5061 - val_loss: 0.8961 - val_precision: 0.5661 - val_recall: 0.4918 - val_fmeasure: 0.5262 - val_categorical_accuracy: 0.5473\n",
      "Epoch 4/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.8946 - precision: 0.5400 - recall: 0.3871 - fmeasure: 0.4505 - categorical_accuracy: 0.5192 - val_loss: 0.8516 - val_precision: 0.5896 - val_recall: 0.5309 - val_fmeasure: 0.5586 - val_categorical_accuracy: 0.5750\n",
      "Epoch 5/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.8639 - precision: 0.5657 - recall: 0.4410 - fmeasure: 0.4953 - categorical_accuracy: 0.5344 - val_loss: 0.9766 - val_precision: 0.5330 - val_recall: 0.4767 - val_fmeasure: 0.5031 - val_categorical_accuracy: 0.5145\n",
      "Epoch 6/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.8518 - precision: 0.5713 - recall: 0.4585 - fmeasure: 0.5085 - categorical_accuracy: 0.5417 - val_loss: 0.7808 - val_precision: 0.6312 - val_recall: 0.5776 - val_fmeasure: 0.6031 - val_categorical_accuracy: 0.6192\n",
      "Epoch 7/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.8230 - precision: 0.5886 - recall: 0.4828 - fmeasure: 0.5298 - categorical_accuracy: 0.5686 - val_loss: 0.7942 - val_precision: 0.6010 - val_recall: 0.5687 - val_fmeasure: 0.5844 - val_categorical_accuracy: 0.5914\n",
      "Epoch 8/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.8182 - precision: 0.6157 - recall: 0.5212 - fmeasure: 0.5643 - categorical_accuracy: 0.5940 - val_loss: 0.7662 - val_precision: 0.6177 - val_recall: 0.5788 - val_fmeasure: 0.5976 - val_categorical_accuracy: 0.6091\n",
      "Epoch 9/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.7959 - precision: 0.6234 - recall: 0.5308 - fmeasure: 0.5731 - categorical_accuracy: 0.5973 - val_loss: 0.7493 - val_precision: 0.6346 - val_recall: 0.6179 - val_fmeasure: 0.6261 - val_categorical_accuracy: 0.6293\n",
      "Epoch 10/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.7704 - precision: 0.6287 - recall: 0.5575 - fmeasure: 0.5907 - categorical_accuracy: 0.6082 - val_loss: 0.7663 - val_precision: 0.6126 - val_recall: 0.5864 - val_fmeasure: 0.5992 - val_categorical_accuracy: 0.6040\n",
      "Epoch 11/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.7652 - precision: 0.6438 - recall: 0.5715 - fmeasure: 0.6053 - categorical_accuracy: 0.6244 - val_loss: 0.8075 - val_precision: 0.5913 - val_recall: 0.5687 - val_fmeasure: 0.5798 - val_categorical_accuracy: 0.5902\n",
      "Epoch 12/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.7369 - precision: 0.6522 - recall: 0.5862 - fmeasure: 0.6173 - categorical_accuracy: 0.6322 - val_loss: 0.8944 - val_precision: 0.5908 - val_recall: 0.5624 - val_fmeasure: 0.5762 - val_categorical_accuracy: 0.5826\n",
      "Epoch 13/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.7263 - precision: 0.6562 - recall: 0.5977 - fmeasure: 0.6255 - categorical_accuracy: 0.6386 - val_loss: 0.9180 - val_precision: 0.5404 - val_recall: 0.5296 - val_fmeasure: 0.5349 - val_categorical_accuracy: 0.5385\n",
      "Epoch 14/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.6981 - precision: 0.6792 - recall: 0.6202 - fmeasure: 0.6482 - categorical_accuracy: 0.6609 - val_loss: 0.7875 - val_precision: 0.6428 - val_recall: 0.6293 - val_fmeasure: 0.6359 - val_categorical_accuracy: 0.6431\n",
      "Epoch 15/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.6999 - precision: 0.6778 - recall: 0.6273 - fmeasure: 0.6515 - categorical_accuracy: 0.6598 - val_loss: 0.8056 - val_precision: 0.6326 - val_recall: 0.6129 - val_fmeasure: 0.6225 - val_categorical_accuracy: 0.6267\n",
      "Epoch 16/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.7082 - precision: 0.6694 - recall: 0.6160 - fmeasure: 0.6414 - categorical_accuracy: 0.6527 - val_loss: 0.7945 - val_precision: 0.6294 - val_recall: 0.6166 - val_fmeasure: 0.6229 - val_categorical_accuracy: 0.6255\n",
      "Epoch 17/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.6890 - precision: 0.7049 - recall: 0.6547 - fmeasure: 0.6788 - categorical_accuracy: 0.6856 - val_loss: 0.7782 - val_precision: 0.6268 - val_recall: 0.6040 - val_fmeasure: 0.6152 - val_categorical_accuracy: 0.6179\n",
      "Epoch 18/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.6689 - precision: 0.7036 - recall: 0.6538 - fmeasure: 0.6777 - categorical_accuracy: 0.6853 - val_loss: 0.8364 - val_precision: 0.5952 - val_recall: 0.5839 - val_fmeasure: 0.5895 - val_categorical_accuracy: 0.5914\n",
      "Epoch 19/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.6531 - precision: 0.7042 - recall: 0.6602 - fmeasure: 0.6814 - categorical_accuracy: 0.6900 - val_loss: 0.7876 - val_precision: 0.6430 - val_recall: 0.6293 - val_fmeasure: 0.6360 - val_categorical_accuracy: 0.6393\n",
      "Epoch 20/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.6451 - precision: 0.7188 - recall: 0.6720 - fmeasure: 0.6945 - categorical_accuracy: 0.7020 - val_loss: 0.7707 - val_precision: 0.6544 - val_recall: 0.6381 - val_fmeasure: 0.6461 - val_categorical_accuracy: 0.6520\n",
      "Epoch 21/35\n",
      "4497/4497 [==============================] - 29s - loss: 0.6263 - precision: 0.7252 - recall: 0.6827 - fmeasure: 0.7032 - categorical_accuracy: 0.7105 - val_loss: 0.8753 - val_precision: 0.5993 - val_recall: 0.5776 - val_fmeasure: 0.5882 - val_categorical_accuracy: 0.5914\n",
      "Epoch 22/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.6249 - precision: 0.7277 - recall: 0.6827 - fmeasure: 0.7043 - categorical_accuracy: 0.7076 - val_loss: 0.7901 - val_precision: 0.6441 - val_recall: 0.6280 - val_fmeasure: 0.6360 - val_categorical_accuracy: 0.6419\n",
      "Epoch 23/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.6244 - precision: 0.7256 - recall: 0.6851 - fmeasure: 0.7047 - categorical_accuracy: 0.7098 - val_loss: 0.7853 - val_precision: 0.6594 - val_recall: 0.6419 - val_fmeasure: 0.6505 - val_categorical_accuracy: 0.6532\n",
      "Epoch 24/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.6191 - precision: 0.7295 - recall: 0.6902 - fmeasure: 0.7093 - categorical_accuracy: 0.7123 - val_loss: 0.9171 - val_precision: 0.6367 - val_recall: 0.6255 - val_fmeasure: 0.6310 - val_categorical_accuracy: 0.6343\n",
      "Epoch 25/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.6081 - precision: 0.7348 - recall: 0.6978 - fmeasure: 0.7157 - categorical_accuracy: 0.7194 - val_loss: 0.8202 - val_precision: 0.6383 - val_recall: 0.6230 - val_fmeasure: 0.6305 - val_categorical_accuracy: 0.6318\n",
      "Epoch 26/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.5855 - precision: 0.7426 - recall: 0.7029 - fmeasure: 0.7221 - categorical_accuracy: 0.7265 - val_loss: 0.8107 - val_precision: 0.6237 - val_recall: 0.6103 - val_fmeasure: 0.6169 - val_categorical_accuracy: 0.6204\n",
      "Epoch 27/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.5766 - precision: 0.7444 - recall: 0.7085 - fmeasure: 0.7259 - categorical_accuracy: 0.7336 - val_loss: 0.7933 - val_precision: 0.6615 - val_recall: 0.6456 - val_fmeasure: 0.6535 - val_categorical_accuracy: 0.6583\n",
      "Epoch 28/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.5828 - precision: 0.7553 - recall: 0.7171 - fmeasure: 0.7356 - categorical_accuracy: 0.7414 - val_loss: 0.8779 - val_precision: 0.6305 - val_recall: 0.6179 - val_fmeasure: 0.6241 - val_categorical_accuracy: 0.6280\n",
      "Epoch 29/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.5808 - precision: 0.7499 - recall: 0.7114 - fmeasure: 0.7301 - categorical_accuracy: 0.7374 - val_loss: 1.0014 - val_precision: 0.5871 - val_recall: 0.5813 - val_fmeasure: 0.5842 - val_categorical_accuracy: 0.5876\n",
      "Epoch 30/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.5546 - precision: 0.7633 - recall: 0.7272 - fmeasure: 0.7447 - categorical_accuracy: 0.7509 - val_loss: 0.9150 - val_precision: 0.6507 - val_recall: 0.6368 - val_fmeasure: 0.6436 - val_categorical_accuracy: 0.6482\n",
      "Epoch 31/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.5671 - precision: 0.7602 - recall: 0.7249 - fmeasure: 0.7421 - categorical_accuracy: 0.7445 - val_loss: 0.8858 - val_precision: 0.5904 - val_recall: 0.5801 - val_fmeasure: 0.5852 - val_categorical_accuracy: 0.5864\n",
      "Epoch 32/35\n",
      "4497/4497 [==============================] - 30s - loss: 0.5340 - precision: 0.7748 - recall: 0.7454 - fmeasure: 0.7597 - categorical_accuracy: 0.7601 - val_loss: 0.8861 - val_precision: 0.6444 - val_recall: 0.6330 - val_fmeasure: 0.6387 - val_categorical_accuracy: 0.6419\n",
      "Epoch 33/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.5340 - precision: 0.7783 - recall: 0.7412 - fmeasure: 0.7592 - categorical_accuracy: 0.7645 - val_loss: 0.8434 - val_precision: 0.6217 - val_recall: 0.6053 - val_fmeasure: 0.6133 - val_categorical_accuracy: 0.6154\n",
      "Epoch 34/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.5224 - precision: 0.7876 - recall: 0.7523 - fmeasure: 0.7695 - categorical_accuracy: 0.7698 - val_loss: 0.9839 - val_precision: 0.6356 - val_recall: 0.6242 - val_fmeasure: 0.6298 - val_categorical_accuracy: 0.6293\n",
      "Epoch 35/35\n",
      "4497/4497 [==============================] - 31s - loss: 0.5261 - precision: 0.7814 - recall: 0.7485 - fmeasure: 0.7645 - categorical_accuracy: 0.7665 - val_loss: 0.8653 - val_precision: 0.6430 - val_recall: 0.6293 - val_fmeasure: 0.6360 - val_categorical_accuracy: 0.6343\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[precision,recall,fmeasure,categorical_accuracy])\n",
    "bz=128\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=35, batch_size=bz)\n",
    "model.save_weights('../output/model_compfinalgendermodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust model and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dropout_1', 'lstm_1', 'dense_1', 'dropout_2', 'embedding_2']\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 208, 300)      1745100     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 208, 300)      0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 50)            70200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4)             204         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,815,504\n",
      "Trainable params: 1,815,504\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "model.load_weights('../output/model_compfinalgendermodel.h5')\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "print(layer_dict.keys())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dens=layer_dict['dense_1'].get_weights()\n",
    "lstmw=layer_dict['lstm_1'].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 208, 300)      1745100     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 208, 300)      0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 208, 50)       70200       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 208, 50)       0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 208, 4)        204         dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,815,504\n",
      "Trainable params: 1,815,504\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#layer_dict['lstm_2'].get_weights()\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True,dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "lstmout = LSTM(50,\n",
    "               return_sequences=True,\n",
    "               stateful=False,weights=lstmw)\n",
    "model.add(lstmout)\n",
    "model.add(Dropout(0.5))\n",
    "templayer=TimeDistributed(Dense(len(labels_index), activation='softmax',weights=dens))\n",
    "model.add(templayer)\n",
    "model.load_weights('../output/model_compfinalgendermodel.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/934 [==============================] - 2s     \n"
     ]
    }
   ],
   "source": [
    "outgendernewviz=model.predict(x_test,verbose=1)\n",
    "np.save('../output/model_compfinalgenderdict.npy', index_word) \n",
    "np.save('../output/model_compfinalgenderdictinv.npy', word_index) \n",
    "np.save('../output/model_compfinalgenderoutput.npy', outgendernewviz) \n",
    "np.save('../output/model_compfinalgenderxtestdata.npy', x_test) \n",
    "np.save('../output/model_compfinalgenderytestdata.npy', y_test) \n",
    "thefile = open('../output/model_compfinalgendertextsinput.txt', 'w')\n",
    "for item in textstest:\n",
    "  thefile.write(\"%s\\n\" % item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60437813906452131"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(np.argmax(y_test, axis=1), np.argmax(outgendernewviz[:, 207, :], axis=1), average='macro', pos_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "#flute prediction\n",
    "essay = ['They are important because I like listening to music and playing my flute. I like having friends and I also enjoy being funny sometimes.']\n",
    "test_seq = tokenizer.texts_to_sequences(essay)\n",
    "full_dat = pad_sequences(test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "preds = model.predict(full_dat, verbose=1)\n",
    "word_index = tokenizer.word_index\n",
    "index_word={}\n",
    "for i,x in word_index.items():\n",
    "    index_word[x]=i\n",
    "np.save('../output/flute_iw.npy', index_word)\n",
    "np.save('../output/flute_iw_inv.npy', word_index)\n",
    "np.save('../output/flute_preds.npy', preds)\n",
    "np.save('../output/flute_xdat.npy', full_dat)\n",
    "#np.save('../output/testdat_just.npy', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refit the model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5290, 208)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (6224, 208)\n",
      "Shape of label tensor: (6224, 4)\n",
      "Shape of xtrain tensor: (5290, 208)\n",
      "Shape of ytrain tensor: (5290, 4)\n",
      "Shape of xval tensor: (934, 208)\n",
      "Shape of yval tensor: (934, 4)\n",
      "Preparing embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labelsCombined))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=.15)\n",
    "\n",
    "textstest=[]\n",
    "textsshuff=[]\n",
    "for i in indices:\n",
    "  textsshuff.append(texts[i])\n",
    "index_word={}\n",
    "for i,x in word_index.items():\n",
    "    index_word[x]=i\n",
    "textstest=textsshuff[:nb_val_samples]\n",
    "\n",
    "thefile = open('../output/gendercleantimedistmodeltesttexts.txt', 'w')\n",
    "for item in textstest:\n",
    "  thefile.write(\"%s\\n\" % item)  \n",
    "\n",
    "np.save('../output/gendercleantimedistmodelxtest.npy', x_test)\n",
    "np.save('../output/gendercleantimedistmodelytest.npy', y_test)\n",
    "\n",
    "print('Shape of xtrain tensor:', x_train.shape)\n",
    "print('Shape of ytrain tensor:', y_train.shape)\n",
    "print('Shape of xval tensor:', x_val.shape)\n",
    "print('Shape of yval tensor:', y_val.shape)\n",
    "#print('Shape of xtest tensor:', x_test.shape)\n",
    "#print('Shape of ytest tensor:', y_test.shape)\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "# prepare embedding matrix\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(nb_words + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 208, 300)      1745100     embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 208, 300)      0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 50)            70200       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 50)            0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 4)             204         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,815,504\n",
      "Trainable params: 1,815,504\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True,dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels_index), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model\n",
    "\n",
    "I'm fitting it to all the data here, so as to make predictions using novel sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 208, 300)      1745100     embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 208, 300)      0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 50)            70200       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 50)            0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 4)             204         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,815,504\n",
      "Trainable params: 1,815,504\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 5290 samples, validate on 934 samples\n",
      "Epoch 1/35\n",
      "5290/5290 [==============================] - 35s - loss: 1.2333 - precision: 0.4652 - recall: 0.0896 - fmeasure: 0.1391 - categorical_accuracy: 0.3811 - val_loss: 0.9790 - val_precision: 0.5068 - val_recall: 0.3073 - val_fmeasure: 0.3822 - val_categorical_accuracy: 0.4968\n",
      "Epoch 2/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.9958 - precision: 0.5147 - recall: 0.2843 - fmeasure: 0.3649 - categorical_accuracy: 0.4747 - val_loss: 0.8803 - val_precision: 0.5402 - val_recall: 0.3544 - val_fmeasure: 0.4274 - val_categorical_accuracy: 0.5257\n",
      "Epoch 3/35\n",
      "5290/5290 [==============================] - 34s - loss: 0.9323 - precision: 0.5271 - recall: 0.3429 - fmeasure: 0.4149 - categorical_accuracy: 0.5004 - val_loss: 0.9108 - val_precision: 0.5616 - val_recall: 0.4165 - val_fmeasure: 0.4779 - val_categorical_accuracy: 0.5332\n",
      "Epoch 4/35\n",
      "5290/5290 [==============================] - 34s - loss: 0.9059 - precision: 0.5426 - recall: 0.3796 - fmeasure: 0.4460 - categorical_accuracy: 0.5062 - val_loss: 0.8225 - val_precision: 0.5533 - val_recall: 0.5043 - val_fmeasure: 0.5276 - val_categorical_accuracy: 0.5407\n",
      "Epoch 5/35\n",
      "5290/5290 [==============================] - 34s - loss: 0.8675 - precision: 0.5677 - recall: 0.4270 - fmeasure: 0.4871 - categorical_accuracy: 0.5397 - val_loss: 0.7951 - val_precision: 0.5727 - val_recall: 0.5107 - val_fmeasure: 0.5397 - val_categorical_accuracy: 0.5664\n",
      "Epoch 6/35\n",
      "5290/5290 [==============================] - 36s - loss: 0.8448 - precision: 0.5870 - recall: 0.4654 - fmeasure: 0.5187 - categorical_accuracy: 0.5522 - val_loss: 0.7787 - val_precision: 0.5952 - val_recall: 0.5471 - val_fmeasure: 0.5700 - val_categorical_accuracy: 0.5857\n",
      "Epoch 7/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.8233 - precision: 0.5903 - recall: 0.4837 - fmeasure: 0.5314 - categorical_accuracy: 0.5637 - val_loss: 0.7710 - val_precision: 0.6160 - val_recall: 0.5610 - val_fmeasure: 0.5869 - val_categorical_accuracy: 0.5889\n",
      "Epoch 8/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.8101 - precision: 0.6079 - recall: 0.4970 - fmeasure: 0.5465 - categorical_accuracy: 0.5762 - val_loss: 0.7817 - val_precision: 0.5973 - val_recall: 0.5546 - val_fmeasure: 0.5751 - val_categorical_accuracy: 0.5792\n",
      "Epoch 9/35\n",
      "5290/5290 [==============================] - 34s - loss: 0.7805 - precision: 0.6119 - recall: 0.5198 - fmeasure: 0.5617 - categorical_accuracy: 0.5870 - val_loss: 0.7601 - val_precision: 0.6151 - val_recall: 0.5632 - val_fmeasure: 0.5879 - val_categorical_accuracy: 0.5996\n",
      "Epoch 10/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.7703 - precision: 0.6290 - recall: 0.5427 - fmeasure: 0.5824 - categorical_accuracy: 0.6011 - val_loss: 0.7919 - val_precision: 0.6101 - val_recall: 0.5846 - val_fmeasure: 0.5970 - val_categorical_accuracy: 0.5985\n",
      "Epoch 11/35\n",
      "5290/5290 [==============================] - 34s - loss: 0.7659 - precision: 0.6395 - recall: 0.5618 - fmeasure: 0.5980 - categorical_accuracy: 0.6170 - val_loss: 0.7336 - val_precision: 0.6435 - val_recall: 0.6167 - val_fmeasure: 0.6298 - val_categorical_accuracy: 0.6349\n",
      "Epoch 12/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.7435 - precision: 0.6489 - recall: 0.5788 - fmeasure: 0.6116 - categorical_accuracy: 0.6318 - val_loss: 0.7439 - val_precision: 0.6287 - val_recall: 0.6039 - val_fmeasure: 0.6160 - val_categorical_accuracy: 0.6199\n",
      "Epoch 13/35\n",
      "5290/5290 [==============================] - 37s - loss: 0.7451 - precision: 0.6463 - recall: 0.5766 - fmeasure: 0.6093 - categorical_accuracy: 0.6267 - val_loss: 0.7375 - val_precision: 0.6363 - val_recall: 0.6124 - val_fmeasure: 0.6241 - val_categorical_accuracy: 0.6296\n",
      "Epoch 14/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.7262 - precision: 0.6627 - recall: 0.5981 - fmeasure: 0.6286 - categorical_accuracy: 0.6444 - val_loss: 0.8347 - val_precision: 0.6209 - val_recall: 0.5846 - val_fmeasure: 0.6021 - val_categorical_accuracy: 0.5996\n",
      "Epoch 15/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.7191 - precision: 0.6674 - recall: 0.6070 - fmeasure: 0.6356 - categorical_accuracy: 0.6497 - val_loss: 0.7592 - val_precision: 0.6425 - val_recall: 0.6221 - val_fmeasure: 0.6320 - val_categorical_accuracy: 0.6338\n",
      "Epoch 16/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.7012 - precision: 0.6838 - recall: 0.6191 - fmeasure: 0.6498 - categorical_accuracy: 0.6592 - val_loss: 0.7970 - val_precision: 0.6165 - val_recall: 0.5964 - val_fmeasure: 0.6062 - val_categorical_accuracy: 0.6113\n",
      "Epoch 17/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6971 - precision: 0.6850 - recall: 0.6278 - fmeasure: 0.6550 - categorical_accuracy: 0.6673 - val_loss: 0.7622 - val_precision: 0.6288 - val_recall: 0.6060 - val_fmeasure: 0.6171 - val_categorical_accuracy: 0.6210\n",
      "Epoch 18/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6809 - precision: 0.6970 - recall: 0.6435 - fmeasure: 0.6690 - categorical_accuracy: 0.6803 - val_loss: 0.7324 - val_precision: 0.6454 - val_recall: 0.6296 - val_fmeasure: 0.6374 - val_categorical_accuracy: 0.6392\n",
      "Epoch 19/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6721 - precision: 0.7022 - recall: 0.6488 - fmeasure: 0.6743 - categorical_accuracy: 0.6824 - val_loss: 0.7540 - val_precision: 0.6396 - val_recall: 0.6178 - val_fmeasure: 0.6285 - val_categorical_accuracy: 0.6317\n",
      "Epoch 20/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6462 - precision: 0.7176 - recall: 0.6698 - fmeasure: 0.6927 - categorical_accuracy: 0.6981 - val_loss: 0.7719 - val_precision: 0.6416 - val_recall: 0.6242 - val_fmeasure: 0.6327 - val_categorical_accuracy: 0.6370\n",
      "Epoch 21/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6499 - precision: 0.7105 - recall: 0.6658 - fmeasure: 0.6873 - categorical_accuracy: 0.6955 - val_loss: 0.8056 - val_precision: 0.6377 - val_recall: 0.6253 - val_fmeasure: 0.6314 - val_categorical_accuracy: 0.6349\n",
      "Epoch 22/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6436 - precision: 0.7075 - recall: 0.6660 - fmeasure: 0.6860 - categorical_accuracy: 0.6941 - val_loss: 0.7456 - val_precision: 0.6418 - val_recall: 0.6328 - val_fmeasure: 0.6372 - val_categorical_accuracy: 0.6381\n",
      "Epoch 23/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6281 - precision: 0.7172 - recall: 0.6747 - fmeasure: 0.6952 - categorical_accuracy: 0.7019 - val_loss: 0.8018 - val_precision: 0.6182 - val_recall: 0.6028 - val_fmeasure: 0.6103 - val_categorical_accuracy: 0.6124\n",
      "Epoch 24/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6183 - precision: 0.7324 - recall: 0.6877 - fmeasure: 0.7093 - categorical_accuracy: 0.7208 - val_loss: 0.7695 - val_precision: 0.6216 - val_recall: 0.6113 - val_fmeasure: 0.6164 - val_categorical_accuracy: 0.6167\n",
      "Epoch 25/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.6100 - precision: 0.7342 - recall: 0.6934 - fmeasure: 0.7131 - categorical_accuracy: 0.7163 - val_loss: 0.8786 - val_precision: 0.6183 - val_recall: 0.6039 - val_fmeasure: 0.6110 - val_categorical_accuracy: 0.6103\n",
      "Epoch 26/35\n",
      "5290/5290 [==============================] - 36s - loss: 0.6062 - precision: 0.7360 - recall: 0.6979 - fmeasure: 0.7163 - categorical_accuracy: 0.7214 - val_loss: 0.8106 - val_precision: 0.6181 - val_recall: 0.6081 - val_fmeasure: 0.6131 - val_categorical_accuracy: 0.6178\n",
      "Epoch 27/35\n",
      "5290/5290 [==============================] - 34s - loss: 0.5940 - precision: 0.7392 - recall: 0.7038 - fmeasure: 0.7210 - categorical_accuracy: 0.7261 - val_loss: 0.7840 - val_precision: 0.6306 - val_recall: 0.6188 - val_fmeasure: 0.6247 - val_categorical_accuracy: 0.6263\n",
      "Epoch 28/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.5838 - precision: 0.7489 - recall: 0.7102 - fmeasure: 0.7290 - categorical_accuracy: 0.7365 - val_loss: 0.8326 - val_precision: 0.6349 - val_recall: 0.6199 - val_fmeasure: 0.6273 - val_categorical_accuracy: 0.6306\n",
      "Epoch 29/35\n",
      "5290/5290 [==============================] - 36s - loss: 0.5626 - precision: 0.7643 - recall: 0.7257 - fmeasure: 0.7444 - categorical_accuracy: 0.7501 - val_loss: 0.7774 - val_precision: 0.6442 - val_recall: 0.6306 - val_fmeasure: 0.6373 - val_categorical_accuracy: 0.6424\n",
      "Epoch 30/35\n",
      "5290/5290 [==============================] - 36s - loss: 0.5688 - precision: 0.7572 - recall: 0.7234 - fmeasure: 0.7398 - categorical_accuracy: 0.7465 - val_loss: 0.8214 - val_precision: 0.6439 - val_recall: 0.6253 - val_fmeasure: 0.6344 - val_categorical_accuracy: 0.6349\n",
      "Epoch 31/35\n",
      "5290/5290 [==============================] - 37s - loss: 0.5396 - precision: 0.7762 - recall: 0.7446 - fmeasure: 0.7600 - categorical_accuracy: 0.7624 - val_loss: 0.8425 - val_precision: 0.6459 - val_recall: 0.6349 - val_fmeasure: 0.6404 - val_categorical_accuracy: 0.6424\n",
      "Epoch 32/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.5488 - precision: 0.7727 - recall: 0.7431 - fmeasure: 0.7576 - categorical_accuracy: 0.7607 - val_loss: 0.9038 - val_precision: 0.6390 - val_recall: 0.6253 - val_fmeasure: 0.6320 - val_categorical_accuracy: 0.6317\n",
      "Epoch 33/35\n",
      "5290/5290 [==============================] - 37s - loss: 0.5272 - precision: 0.7783 - recall: 0.7490 - fmeasure: 0.7633 - categorical_accuracy: 0.7656 - val_loss: 0.8689 - val_precision: 0.6168 - val_recall: 0.6049 - val_fmeasure: 0.6108 - val_categorical_accuracy: 0.6146\n",
      "Epoch 34/35\n",
      "5290/5290 [==============================] - 36s - loss: 0.5417 - precision: 0.7750 - recall: 0.7420 - fmeasure: 0.7581 - categorical_accuracy: 0.7626 - val_loss: 0.8509 - val_precision: 0.6185 - val_recall: 0.6103 - val_fmeasure: 0.6144 - val_categorical_accuracy: 0.6178\n",
      "Epoch 35/35\n",
      "5290/5290 [==============================] - 35s - loss: 0.5331 - precision: 0.7794 - recall: 0.7431 - fmeasure: 0.7608 - categorical_accuracy: 0.7631 - val_loss: 0.8203 - val_precision: 0.6376 - val_recall: 0.6274 - val_fmeasure: 0.6324 - val_categorical_accuracy: 0.6338\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[precision,recall,fmeasure,categorical_accuracy])\n",
    "print(model.summary())\n",
    "bz=128\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=35, batch_size=bz)\n",
    "model.save_weights('../output/full_finalgendermodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, restructure the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 208, 300)      1745100     embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 208, 300)      0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 50)            70200       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 50)            0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 4)             204         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,815,504\n",
      "Trainable params: 1,815,504\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['embedding_5', 'dense_3', 'lstm_3', 'dropout_5', 'dropout_6']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "model.load_weights('../output/full_finalgendermodel.h5')\n",
    "model.summary()\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "layer_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dens=layer_dict['dense_3'].get_weights()\n",
    "lstmw=layer_dict['lstm_3'].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_6 (Embedding)          (None, 208, 300)      1745100     embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 208, 300)      0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 208, 50)       70200       dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 208, 50)       0           lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribut (None, 208, 4)        204         dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,815,504\n",
      "Trainable params: 1,815,504\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(nb_words + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True,dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "lstmout = LSTM(50,\n",
    "               return_sequences=True,\n",
    "               stateful=False,weights=lstmw)\n",
    "model.add(lstmout)\n",
    "model.add(Dropout(0.5))\n",
    "templayer=TimeDistributed(Dense(len(labels_index), activation='softmax',weights=dens))\n",
    "model.add(templayer)\n",
    "model.load_weights('../output/full_finalgendermodel.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here, I make some novel sentences to pass to the network\n",
    "(Justification with relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "texts = ['Athletic ability is important to me because ', \n",
    "         'Art is important to me because ', \n",
    "         'Being smart is important to me because ', \n",
    "         'Getting good grades is important to me because ', \n",
    "         'Creativity is important to me because ', \n",
    "         'Independence is important to me because ', \n",
    "         'Social groups are important to me because ', \n",
    "         'Music is important to me because ', \n",
    "         'Politics is important to me because ', \n",
    "         'Relationships is important to me because ', \n",
    "         'Religion is important to me because ', \n",
    "         'Sense of humor is important to me because ', \n",
    "         'Living in the moment is important to me because ']\n",
    "\n",
    "justification = ['my friends', 'my family', 'my grandparents', 'my parents', 'my teacher', \n",
    "                 'my friend', 'my dad', 'my mom', 'my sister', 'my brother', \n",
    "                 'my mother', 'my father', 'my cousin', 'my aunt', 'my uncle']\n",
    "\n",
    "\n",
    "a = list(itertools.product(texts, justification))\n",
    "combos = []\n",
    "value = []\n",
    "just = []\n",
    "for i in a:\n",
    "    combos.append(i[0]+i[1])\n",
    "    value.append(i[0].split()[0])\n",
    "    just.append(i[1].split()[1])\n",
    "df = pd.DataFrame({'text':combos,\n",
    "                  'value':value,\n",
    "                  'justification':just})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions and save important bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(combos)\n",
    "full_dat = pad_sequences(test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "preds = model.predict(full_dat, verbose=1)\n",
    "word_index = tokenizer.word_index\n",
    "index_word={}\n",
    "for i,x in word_index.items():\n",
    "    index_word[x]=i\n",
    "np.save('../output/testsentiw_just.npy', index_word)\n",
    "np.save('../output/testsentiw_inv_just.npy', word_index)\n",
    "np.save('../output/testsentpreds_just.npy', preds)\n",
    "np.save('../output/testsentxdat_just.npy', full_dat)\n",
    "np.save('../output/testdat_just.npy', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here, I make some novel sentences to pass to the network\n",
    "(Justification with the self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = ['Athletic ability is important to me because ', \n",
    "         'Art is important to me because ', \n",
    "         'Being smart is important to me because ', \n",
    "         'Getting good grades is important to me because ', \n",
    "         'Creativity is important to me because ', \n",
    "         'Independence is important to me because ', \n",
    "         'Social groups are important to me because ', \n",
    "         'Music is important to me because ', \n",
    "         'Politics is important to me because ', \n",
    "         'Relationships is important to me because ', \n",
    "         'Religion is important to me because ', \n",
    "         'Sense of humor is important to me because ', \n",
    "         'Living in the moment is important to me because ']\n",
    "\n",
    "justification = ['I want', 'I need', 'I will', 'I have', 'I can', \n",
    "                 'I feel', 'I should', 'I would', 'I hope', 'I am', \n",
    "                 'I get', 'I might', 'I use', 'I like', 'I take']\n",
    "\n",
    "\n",
    "a = list(itertools.product(texts, justification))\n",
    "combos = []\n",
    "value = []\n",
    "just = []\n",
    "for i in a:\n",
    "    combos.append(i[0]+i[1])\n",
    "    value.append(i[0].split()[0])\n",
    "    just.append(i[1].split()[1])\n",
    "df = pd.DataFrame({'text':combos,\n",
    "                  'value':value,\n",
    "                  'justification':just})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions and save important bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(combos)\n",
    "full_dat = pad_sequences(test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "preds = model.predict(full_dat, verbose=1)\n",
    "word_index = tokenizer.word_index\n",
    "index_word={}\n",
    "for i,x in word_index.items():\n",
    "    index_word[x]=i\n",
    "np.save('../output/testsentiw_justself.npy', index_word)\n",
    "np.save('../output/testsentiw_inv_justself.npy', word_index)\n",
    "np.save('../output/testsentpreds_justself.npy', preds)\n",
    "np.save('../output/testsentxdat_justself.npy', full_dat)\n",
    "np.save('../output/testdat_justself.npy', df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
